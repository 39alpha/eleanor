# ###
# ### Helmsman
# ### Controls the execution of orders generated by the navigator
# ### Tucker Ely, Douglas G. Moore, Cole Mathis

import multiprocessing
import os
import re
import shutil
import time
import queue

import numpy as np
import pandas as pd

from tqdm import tqdm

# ### local imports
from .hanger.db_comms import execute_query
from .hanger.db_comms import establish_database_connection, retrieve_records, get_column_names
from .hanger.eq36 import eq3, eq6
from .hanger.data0_tools import determine_species_set, data0_suffix
from .hanger.tool_room import mk_check_del_directory, mine_pickup_lines, grab_float
from .hanger.tool_room import grab_lines, grab_str, WorkingDirectory


def Helmsman(camp, ord_id=None):
    """
    Keeping with the naval terminology:
        The Navigator charts where to go.

        Then the helmsman guides the ship there, using sailors to do the necessary work.

    Thus:
        Navigator decides the region of parameter space to be explored, by issuing orders that are
        written in the `vs` (variable space) table. Each order contains a collections of discrete
        `vs` points distributed about the parameter space. The dimension of the parameter space
        thermodynamic (temperature, pressure, total C, total Fe, etc.). Each point in this parameter
        space contains variables (dimensions) sufficient to describes a closed thermodynamic system.

        The goal of the helmsman is to solve for the equilibrium behavior of each of these points
        distributed about the variable space (vs).

        The Helmsman does this by spawning a small number of sailors (with number of sailors
        determined by system capabilities), assigning each a vs point that they will thermodynamic
        'solve' in succession until all points have been solved.

        Each vs point assigned to a sailor, contains enough information to define a closed
        thermodynamic system. The sailor employs EQ3/6 to determine the equilibrium
        characteristic of the system defined by the vs point, thus generating an associated point
        in the equilibrium space (`es`) table.

    :param camp: loaded campaign
    :type camp: :class:`Campaign` instance

    :param ord_id: order number
    :type ord_id: int


    """

    with camp.working_directory():
        conn = establish_database_connection(camp)

        elements, aq_sp, solids, ss, gasses = determine_species_set(path='huffer/')

        # retrieve issued order 'ord_id'
        order_query = ('SELECT * FROM `vs` WHERE `code` = 0',
                       'AND `uuid` NOT IN (SELECT `uuid` FROM `es`)')
        if ord_id is not None:
            order_query += f' AND `ord` = {ord_id}'
        rec = retrieve_records(conn, order_query)
        vs_col_names = get_column_names(conn, 'vs')
        es_col_names = get_column_names(conn, 'es')

        conn.close()

    if len(rec) == 0:
        msg = "The Helmsman found no unexecuted points"
        if ord_id is not None:
            msg += f" for order {ord_id}"
        print(msg)
        return

    date = time.strftime("%Y-%m-%d", time.gmtime())

    # build order-specific local working directory
    order_path = os.path.join(camp.campaign_dir, 'order_{}'.format(ord_id))
    mk_check_del_directory(order_path)
    os.chdir(order_path)

    start = time.time()  # for diagnostic times
    if ord_id is None:
        print(f"Processing all unfulfilled orders ({len(rec)} points)")
    else:
        print(f"Processing Order {ord_id} ({len(rec)} points)")
    cores = 4  # TODO: This doesn't make no damn sense, detect or pass as an argument

    with WorkingDirectory(order_path):

        # build vs/es queues
        queue_manager = multiprocessing.Manager()
        vs_queue = queue_manager.Queue()
        es_queue = queue_manager.Queue()

        keep_running_yoeman = multiprocessing.Value('b', True)
        yoeman_process = multiprocessing.Process(target=yoeman, args=(camp, keep_running_yoeman,
                                                 vs_queue, es_queue, len(rec)))
        yoeman_process.start()

        # ##############   Multiprocessing  ##################
        with multiprocessing.Pool(processes=cores) as pool:
            _ = pool.starmap(sailor, zip([camp] * len(rec),
                                         [order_path] * len(rec),
                                         [vs_queue] * len(rec),
                                         [es_queue] * len(rec),
                                         [date] * len(rec),
                                         rec,
                                         [elements] * len(rec),
                                         [ss] * len(rec),
                                         [vs_col_names] * len(rec),
                                         [es_col_names] * len(rec)))

        #  check to see if queues are empty to kill
        while not vs_queue.empty():
            time.sleep(1)
        while not es_queue.empty():
            time.sleep(1)

        with keep_running_yoeman.get_lock():
            keep_running_yoeman.value = False

    yoeman_process.join()

    print(f'\nOrder {ord_id} complete.')
    print(f'        total time: {round(time.time() - start, 4)}')
    print(f'        time/point: {round((time.time() - start) / len(rec), 4)}')
    print(f'   time/point/core: {round((cores * (time.time() - start)) / len(rec), 4)}\n')


def sailor(camp, order_path, vs_queue, es_queue, date, dat,
           elements, ss, vs_col_names, es_col_names, keep_every_n_files=1):
    """
    Each sailor manages the execution of all geochemically model steps associated
    with a single vs point in the Variable Space (VS).
    These steps included:

        (1) build 3i
        (2) run 3i
        (3) build 6i
        (4) run 6i
        (5) mine 6o

    :param camp: loaded campaign
    :type camp: :class:`Campaign` instance

    :param order_path: local directory path for the current order
    :type order_path: str

    :param vs_queue: a waiting list of lines that need to be written to vs table
    :type vs_queue: class 'multiprocessing.managers.AutoProxy[Queue]

    :param es_queue: a queue of pandas data frames that need to be written to es table
    :type es_queue: class 'multiprocessing.managers.AutoProxy[Queue]

    :param date: birthdate of order
    :type data: str

    :param dat: all vs specific data need by the sailor to complete mission.
    :type dat: list

    :param elements: list of loaded element, excepting O and H
    :type elements: list of strings

    :param ss: list of loaded solid solutions
    :type ss: list of strings

    :param vs_col_names: column headers in vs table. If a value in the eq3/6 run files is not in
                         the column names, then it is not captured.
    :type vs_col_names: list of strings

    :param es_col_names: column headers in es table. If a value in the eq3/6 run files is not in
                         the column names, then it is not captured.

    :type es_col_names: list of strings

    :param keep_every_n_files: keep every n (multiple) files. All run files get deleted after being
                               processed into the VS/ES sql database, as they are collectively very
                               large. A subset of files can be kept here for later manual
                               This argument allows you to keep the raw data eq3/6 for a subset of
                               runs so that you can evaluate the output directly. the sql codes grab
                               a lot of the EQ3/6 run information, but not all of it.
    :type keep_every_n_files: int

    """
    run_num = str(dat[3])
    file = '{}.3i'.format(run_num)
    if int(run_num) in [int(idx) for idx in np.arange(0, 10000000, keep_every_n_files)]:
        delete_after_running = False
    else:
        delete_after_running = True

    master_dict = {}
    for i, j in zip(vs_col_names, dat):
        master_dict[i] = j

    state_dict = {}
    for i in camp.vs_state:
        state_dict[i] = master_dict[i]

    basis_dict = {}
    for i in camp.vs_basis:
        basis_dict[i] = master_dict[i]

    rnt_dict = {}
    rnt_keys = list(camp.target_rnt.keys())

    for i in range(len(rnt_keys)):
        name = rnt_keys[i]
        rnt_type = camp.target_rnt[name][0]
        morr = master_dict['{}_morr'.format(name)]
        rkb1 = master_dict['{}_rkb1'.format(name)]
        rnt_dict[name] = [rnt_type, morr, rkb1]

    # ### build and enter temp directory
    mk_check_del_directory(run_num)
    os.chdir(run_num)  # TODO: Check whether we should do this here

    # ### select proper data0
    suffix = data0_suffix(state_dict['T_cel'], state_dict['P_bar'])

    # ### build and execute 3i
    camp.local_3i.write(file, state_dict, basis_dict, master_dict['cb'], output_details='n')
    data1_file = os.path.join(camp.data0_dir, "data1." + suffix)
    out, err = eq3(data1_file, file)
    # above variables not currently used

    if not os.path.isfile(file[:-1] + 'p'):
        # ### check 3p not generated. Then rebuild 3i and rerun as
        # ### 'v = verbose' to generate diagnostics. This will of
        # ### course not help converge the file, but will provide the
        # ### information needed to map evidence of the failure for
        # ### future code to assess.
        reset_sailor(order_path, vs_queue, file, dat[0], 30,
                     delete_local=delete_after_running)
        return

    # process 3p file
    try:
        pickup = mine_pickup_lines('.', file[:-1] + 'p', 's')
    except Exception as e:
        # cannot mine pickup lines
        print('{}\n  {}\n'.format(file, e))
        reset_sailor(order_path, vs_queue, file, dat[0], 31,
                     delete_local=delete_after_running)
        return

    camp.local_6i.write(file[:-2] + '6i', rnt_dict, pickup, state_dict['T_cel'])
    out, err = eq6(data1_file, file[:-2] + '6i')

    if not os.path.isfile(file[:-2] + '6o'):
        reset_sailor(order_path, vs_queue, file, dat[0], 60,
                     delete_local=delete_after_running)

        return

    run_code, build_df = mine_6o(camp, date, elements, ss, file[:-2] + '6o', dat, es_col_names)

    if run_code == 100:
        # ### write to ES
        es_queue.put(build_df)

    reset_sailor(order_path, vs_queue, file, dat[0], run_code,
                 delete_local=delete_after_running)


def mine_6o(camp, date, elements, ss, file, dat, col_names):
    """
    open and mine the eq6 output file ('file'.6o) for all of the run information
    with associated columns in the ES table.

    :param camp: loaded campaign
    :type camp: :class:`Campaign` instance

    :param date: birthdate of order
    :type data: str

    :param elements: list of loaded element, excepting O and H
    :type elements: list of strings

    :param ss: list of loaded solid solutions
    :type ss: list of strings

    :param file: 'file'.6o file name
    :type file: str

    :param dat: all vs specific data need by the sailor to complete mission.
    :type dat: list

    :param col_names: ES table columns
    :type col_names: list of strings
    """

    build_dict = {k: [] for k in col_names}

    lines = grab_lines(file)  # 6o file

    run_code = 0  # default to un-run file '0'
    search_for_xi = False
    for i in range(len(lines) - 1, 0, -1):
        # ## search from bottom of file
        if '---  The reaction path has terminated early ---' in lines[i]:
            # ## do not process 6o
            build_df = pd.DataFrame.from_dict(build_dict)
            return 70, build_df
        elif '---  The reaction path has terminated normally ---' in lines[i]:
            run_code = 100
            # Healthy file. Search for index of the last xi step
            search_for_xi = True
        elif search_for_xi and '                Log Xi=' in lines[i]:
            # The first appearance of this, when searching from the bottom
            # is the final EQ step of interest for populating ES.
            last_xi_step_begins = i  # grab index for later.
            break

    if run_code == 0:
        # run code has not be altered, therefore unknown error
        build_df = pd.DataFrame.from_dict(build_dict)
        return 61, build_df

    # populate ES table
    for i in range(len(lines)):
        if '   Affinity of the overall irreversible reaction=' in lines[i]:
            # the first instance of this line is xi = 0.0
            # (initial disequilibria with target mineral)
            build_dict["initial_aff"] = [grab_float(lines[i], -2)]
            break

    # search from beginning of last xi step (set in last_xi_step_begins)
    # grab xi_max. since initial index contains log Xi.
    build_dict['xi_max'] = [grab_float(lines[last_xi_step_begins], -1)]

    for i in range(last_xi_step_begins, len(lines)):
        if re.findall('^\n', lines[i]):
            pass

        elif ' Temperature=' in lines[i]:
            build_dict['T_cel'] = [grab_float(lines[i], -2)]

        elif ' Pressure=' in lines[i]:
            build_dict['P_bar'] = [grab_float(lines[i], -2)]

        elif ' --- Elemental Composition' in lines[i]:
            x = 4
            while not re.findall('^\n', lines[i + x]):
                if grab_str(lines[i + x], 0) in elements:
                    # log molality
                    this_dat = [np.round(np.log10(grab_float(lines[i + x], -1)), 6)]
                    build_dict['{}'.format(grab_str(lines[i + x], 0))] = this_dat
                    x += 1
                else:
                    x += 1

        elif '                Log oxygen fugacity=' in lines[i]:
            build_dict['fO2'] = [grab_float(lines[i], -1)]

        elif '              Log activity of water=' in lines[i]:
            build_dict['aH2O'] = [grab_float(lines[i], -1)]

        elif '                 Ionic strength (I)=' in lines[i]:
            build_dict['ionic'] = [grab_float(lines[i], -2)]

        elif '                 Solutes (TDS) mass=' in lines[i]:
            build_dict['tds'] = [grab_float(lines[i], -2)]

        elif '              Aqueous solution mass=' in lines[i]:
            build_dict['soln_mass'] = [grab_float(lines[i], -2)]

        elif '--- Distribution of Aqueous Solute Species ---' in lines[i]:
            x = 4
            while not re.findall('^\n', lines[i + x]):
                if grab_str(lines[i + x], 0) != 'O2(g)':
                    # -1 position is log activity, -3 is log molality
                    build_dict[grab_str(lines[i + x], 0)] = [grab_float(
                        lines[i + x], -1)]
                    x += 1
                else:
                    x += 1
            del x

        elif '--- Summary of Solid Phases (ES) ---' in lines[i]:
            # ### Solids data is stored in a temp_s_dict, to be
            # ### added to the build_df after the file is processed.
            # ### This way 'moles precipitated', if it exists, overwrites
            # ### the affinity data. See notes at the beginning of
            # ### this function for explanation. This temporary
            # ### dictionary is only necessary because the solids
            # ### precipitation moles is reported ahead of the affinity
            # ### data in the 6o file.
            temp_s_dict = {}

            x = 4
            while not re.findall('^\n', lines[i + x]):
                if 'None' not in lines[i + x]:
                    # ## solids value grab_float()'s must reach from the
                    # ## end of the line (-1, -2, etc.)
                    # ## because some solid names contain spaces.
                    # ## Additionally, solid names are grabbed based
                    # ## in-line index as opposed to the grab_str()
                    # ## function, for the same reason.

                    # ### mols
                    temp_s_dict[lines[i + x][:25].strip()] = [grab_float(lines[i + x], -3)]
                    x += 1
                else:
                    x += 1
            del x

        elif '--- Saturation States of Pure Solids ---' in lines[i]:
            x = 4
            while not re.findall('^\n', lines[i + x]):
                if re.findall(r'\*{4}$', lines[i + x]):
                    # ## '******'' fills in the value region for numbers
                    # ## lower than -999.9999. Replace with boundary condition

                    # ## affinity (kcal)
                    build_dict[lines[i + x][:30].strip()] = [float(-999.9999)]
                    x += 1
                elif 'None' not in lines[i + x]:
                    build_dict[lines[i + x][:30].strip()] = [
                        float(lines[i + x][44:55])]
                    x += 1
                else:
                    x += 1
            del x

        elif camp.SS and ' --- Saturation States of Solid Solutions ---' in lines[i]:
            x = 4
            while not re.findall('^\n', lines[i + x]):
                if re.findall(r'\*{4}$', lines[i + x]):
                    # ## '******'' fills in the value region for numbers
                    # ## lower than -999.9999. Replace with boundary condition

                    # ## affinity (kcal)
                    build_dict[lines[i + x][:30].strip()] = [float(-999.9999)]
                    x += 1
                elif 'None' not in lines[i + x]:
                    # ## affinity (kcal)
                    build_dict[lines[i + x][:30].strip()] = [
                        float(lines[i + x][44:55])]
                    x += 1
                else:
                    x += 1
            del x

        elif '    --- Fugacities ---' in lines[i]:
            x = 4
            while not re.findall('^\n', lines[i + x]):

                if 'None' not in lines[i + x]:  # log f
                    if re.findall(r'\*{4}', lines[i + x]):
                        # ## '******'' fills in the value region for numbers
                        # ## lower than -999.9999. Replace with boundary condition

                        # ## affinity (kcal)
                        build_dict[lines[i + x][:30].strip()] = [float(-999.9999)]
                        x += 1
                    else:
                        build_dict[grab_str(lines[i + x], 0)] = [
                            float(lines[i + x][28:41])]
                        x += 1
                else:
                    x += 1
            del x
            break

    for i in temp_s_dict.keys():
        # ## write temp_s_dict[i] to build_df[i]. As temp_s_dict only
        # ## contains solids that actually precipitated, the
        # ## affinity values in build_df[i] can simply be overwritten

        build_dict[i] = temp_s_dict[i]

    build_dict['uuid'] = [dat[0]]
    build_dict['ord'] = [dat[2]]
    build_dict['file'] = [dat[3]]
    build_dict['run'] = [date]
    build_dict['mineral'] = [dat[5]]

    if not camp.SS:
        for i in ss:
            build_dict[i] = [-999999]

    # ## reorganize columns to match es table
    build_df = pd.DataFrame.from_dict(build_dict)

    build_df = build_df[col_names]

    return run_code, build_df


def yoeman(camp, keep_running, write_vs_q, write_es_q, num_points):
    """
    Collecting each sailors df output, and then writing it in
    bulk to sql

    :param camp: loaded campaign
    :type camp: :class:`Campaign` instance

    :param keep_running: should the yoeman continue to run (ie. is there shit
                         left to write to the VS/ES)
    :type keep_running: multiprocessing.value boolean

    :param write_vs_q: queue of lines waiting to be written to vs table
    :type write_vs_q: queue.Queue

    :param write_es_q: queue of DataFrames waiting to be written to vs table
    :type write_es_q: queue.Queue

    :param num_points: number of vs points in the order
    :type num_points: int
    """
    conn = establish_database_connection(camp)

    vs_n_written = 0

    progress = tqdm(total=num_points)

    es_df_list = []
    vs_list = []

    while keep_running.value:

        # ### check that es has something to write
        try:
            es_df = write_es_q.get_nowait()
        except queue.Empty:
            if es_df_list != []:
                total_es_df = pd.concat(es_df_list, ignore_index=True)
                total_es_df.to_sql('es', conn, if_exists='append', index=False)
                es_df_list = []
                progress.update()
        else:
            # add the es_df to the list to be written
            es_df_list.append(es_df)

        # ### check that vs has something to write
        try:
            vs_sql = write_vs_q.get_nowait()
        except queue.Empty:
            # ### write available vs data to sql
            if vs_list != []:
                for vs_point in vs_list:
                    execute_query(conn, vs_point)
                    vs_n_written += 1
                vs_list = []
        else:
            vs_list.append(vs_sql)

        # Make sure to write at least every 100 points
        if len(es_df_list) >= 100:
            total_es_df = pd.concat(es_df_list, ignore_index=True)
            total_es_df.to_sql('es', conn, if_exists='append', index=False)
            es_df_list = []
            progress.update()
        if len(vs_list) >= 100:
            for vs_point in vs_list:
                execute_query(conn, vs_point)
                vs_n_written += 1
            vs_list = []

    return None

def six_o_data_to_sql(conn, table, df):
    """
    Commit the 6o DataFrame to sql

    :param conn: sql database connection
    :type conn: :class: sqlite3.Connection

    :param table: name of sql table
    :type table: str

    :param df: DataFrame contain the 6o information to written to the es table
    :type df: 'pandas.core.frame.DataFrame'

    """
    df.to_sql(table, conn, if_exists='append', index=False)


def reset_sailor(order_path, vs_queue, file, uuid, code, delete_local=False):
    """
    The sailor is finished, for better or worse. Close up shop.

    (1) Report to vs table 'camp_name' via server connection 'conn' the
        exit 'code' for 'file' with unique vs_table id 'uuid'.
    (2) Step back into order folder 'order_path' for next vs point.

    :param order_path: path to order folder
    :type order_path: str

    :param vs_queue: a waiting list of lines that need to be written to vs table
    :type vs_queue: class 'multiprocessing.managers.AutoProxy[Queue]

    :param file: original 3i file name for this vs point 'id_number.3i'
    :type file: str

    :param uuid: 'Universally Unique IDentifier'
    :type uuid: str

    :param code: custom exit codes describing eq3/6 errors
    :type code: int

    :param delete_local: do you want to keep the local folder full of the eq3/6 files?
    :type delete_local: boolean

    """

    sql = """UPDATE vs SET code = {} WHERE uuid = '{}';""".format(code, uuid)
    vs_queue.put(sql)
    os.chdir(order_path)
    if delete_local:
        shutil.rmtree(file[:-3])
